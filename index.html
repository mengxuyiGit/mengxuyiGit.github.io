<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Xuyi Meng</title>

  <meta name="author" content="Xuyi Meng">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon"
    href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Xuyi Meng</name>
                  </p>
                  <p>
                    I am a 1st-year M.S. student studying computer and information science at <a href="https://www.upenn.edu/">University of Pennsylvania</a>,
                    supervised by <a href="https://lingjie0206.github.io/">Prof. Lingjie Liu</a>.
                    Before that, I have acquired my B.E. degree in CS with <strong>highest distinction</strong> from
                    <a href="https://www.ntu.edu.sg/">Nanyang Technological University</a>, Singapore,
                    where I had the great opportunity to work in <a href="<a href="https://www.mmlab-ntu.com/">MMLab@NTU</a>,
                    advised by <a href="https://www.mmlab-ntu.com/person/ccloy/">Prof. Chen Change Loy</a> and <a href="daibo.info">Dr. Daibo</a>.
                    During my undergrad, I also spent a great summer in 2022 visiting <a href="https://www.ucsd.edu/">UCSD</a> and working with <a href="https://cseweb.ucsd.edu/~haosu/">Prof. Hao Su</a>.

                   
                  </p>
                  <p style="text-align:center">
                    <a href="mailto:mengxuyi@seas.upenn.edu">Email</a> &nbsp/&nbsp
                    <a href="data/MengXuyi_CV_2024_Dec2.pdf">CV</a> &nbsp/&nbsp
                    <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp -->
                    <!-- <a href="https://scholar.google.com/citations?hl=en&user=jktWnL8AAAAJ">Google Scholar</a> -->
                    <!-- &nbsp/&nbsp -->
                    <!-- <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp/&nbsp -->
                    <a href="https://github.com/mengxuyiGit/">Github</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">

                  <a href="images/portrait-yslan.JPG"><img style="width:100%;max-width:100%" alt="profile photo"
                      src="images/yslan-indo.jpeg" class="hoverZoomLink"></a>

                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Research</heading>
                  <p>
                    <!-- My interests lie in the intersection of computer vision, computer graphics, and machine learning,
                    particularly in inverse graphics powered by neural rendering,
                    including 3D generative models, shape analysis and 3D avatar, etc. -->
                    <!-- My research direction so far has been focusing on <strong>3D content generation</strong>,
                    particularly harnessing different generative backbone to generate point based rendering or neural rendering.
                    I am also interested in <strong>4D generation and reconstruction</strong>, 
                    where I have had experience in reconstructing human avatar from video data and render in real-time.
                    My research goal is to teach the model to learn rich priors and physics laws in the world 
                    using high dimentional data (3D/4D) through differentiable rendering. -->

                    My research focuses on <strong>3D content generation</strong>,
                    leveraging various generative backbones for point-based and neural rendering. 
                    I am also interested in <strong>4D generation and reconstruction</strong>,
                    with experience in human avatar reconstruction from video data that can be rendered in real-time. 
                    My goal is to develop models that learn rich priors and physical laws 
                    from high-dimensional data (3D/4D) through differentiable rendering.
                    
                  </p>
                  <p>
                  <font color="red"><strong>I am looking for a Ph.D. position in 25 Fall!</strong></font>
                  </p>
                </td>
              </tr>
            </tbody>
          </table>

<!-- ! below section TODO, after new paper accepted. -->
<!-- 
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>News</heading>
                  <p> [2023-06] Joined Google AR as a student researcher, working with <a href="https://www.zhangyinda.com/">Yinda Zhang</a> .</p>
                  <p> [2023-03] Joined Google AR as a student researcher, working with <a href="https://www.zhangyinda.com/">Yinda Zhang</a> .</p>
                </td>
              </tr>
            </tbody>
          </table> -->


          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <!-- iclr 23 -->


              <!-- <div class="teaser-container">
                <img class="teaser" src="/assets/images/EVA3D.gif" alt="EVA3D.gif">
              </div> -->

              <!-- <div class="info-container">

                <p class="title">

                  <a class="title_link" href="https://arxiv.org/abs/2210.04888" target="_blank">EVA3D: Compositional 3D
                    Human Generation from 2D Image Collections
                  </a>

                </p>

                <div class="authors">
                  <a href="https://hongfz16.github.io/" target="_blank">Fangzhou Hong</a>,
                  <a href="https://frozenburning.github.io/" target="_blank"> Zhaoxi Chen</a>,
                  <strong>Yushi Lan</strong>,
                  <a href="https://scholar.google.com/citations?user=lSDISOcAAAAJ&amp;hl=zh-CN" target="_blank">Liang
                    Pan</a>,
                  <a href="https://liuziwei7.github.io" target="_blank">Ziwei Liu</a></p>
                </div>

                <div class="conference">
                  <p><em>International Conference on Learning Representations</em> (<strong>ICLR</strong>), 2023 <span
                      style="color:red;"><strong>(Spotlight)</strong></span></p>
                </div>


                <div class="url">
                  <a href="https://arxiv.org/pdf/2210.04888.pdf" target="_blank">[PDF]</a>
                  <a href="https://hongfz16.github.io/projects/EVA3D.html" target="_blank">[Project Page]</a>
                  <a href="https://www.youtube.com/watch?v=JNV0FJ0aDWM" target="_blank">[Demo]</a>
                  <a href="https://www.unite.ai/creating-full-body-deepfakes-by-combining-multiple-nerfs/"
                    target="_blank">[Press]</a>
                  <a href="https://github.com/hongfz16/EVA3D" target="_blank">[Code]</a>
                  <img src="https://img.shields.io/github/forks/hongfz16/EVA3D?style=social">

                </div>

                <div class="comment">
                  <p>EVA3D is a <strong>high-quality unconditional 3D human generative model</strong> that only requires
                    2D image collections for training.</p>
                </div>

              </div> -->

              <!-- ln3diff -->

              <tr onmouseout="e3dge_stop()" onmouseover="e3dge_start()">
                <!-- <tr> -->
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='e3dge_image'><video width=100% height=100% muted autoplay loop>
                        <source src="images/ln3diff/mast.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                      </video></div>
                    <!-- <img src='images/gaussian3diff/small_teaser.png' width="160"> -->
                  </div>
                  <!-- <p>A sailboat with mast.</p> -->
                  <!-- <script type="text/javascript">
                    function e3dge_start() {
                      document.getElementById('e3dge_image').style.opacity = "1";
                    }

                    function e3dge_stop() {
                      document.getElementById('e3dge_image').style.opacity = "0";
                    }
                    e3dge_stop()
                  </script> -->
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://nirvanalan.github.io/projects/ln3diff/">
                    <papertitle>LN3Diff: Scalable Latent Neural Fields Diffusion for Speedy 3D Generation
                    </papertitle>
                  </a>
                  <br>

                  <a href="https://nirvanalan.github.io/">Yushi Lan</a>,
                  <a href="https://hongfz16.github.io">Fangzhou Hong</a>,
                  <a href="https://williamyang1991.github.io/">Shuai Yang</a>,
                  <a href="https://shangchenzhou.com/">Shangchen Zhou</a>,
                  <strong>Xuyi Meng</strong>,
                  <!-- <a href="https://sg.linkedin.com/in/xuyi-meng-673779208"></a>, -->
                  <a href="https://daibo.info/">Bo Dai</a>,
                  <a href="https://xingangpan.github.io/">Xingang Pan</a>,
                  <a href="https://www.mmlab-ntu.com/person/ccloy/">Chen Change Loy</a>
                  <br>
                  <em>arXiv preprint</em>
                  <br>
                  <a href="https://nirvanalan.github.io/projects/ln3diff/">project page</a>
                  /
                  <a href="https://arxiv.org/pdf/2403.12019.pdf">arXiv</a>

                  <p></p>
                  <p>
                    LN3Diff creates high-quality 3D object mesh from text within 8 SECONDS. 
                  </p>
                </td>
              </tr>

      </tr>

      <tr onmouseout="e3dge_stop()" onmouseover="e3dge_start()">
        <!-- <tr> -->
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <!-- <div class="two" id='e3dge_image'><video width=100% height=100% muted autoplay loop>
                <source src="images/dreamfusion.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video></div> -->
            <img src='images/E3DGE/e3dge.png' width="160">
          </div>
          <!-- <script type="text/javascript">
            function e3dge_start() {
              document.getElementById('e3dge_image').style.opacity = "1";
            }

            function e3dge_stop() {
              document.getElementById('e3dge_image').style.opacity = "0";
            }
            e3dge_stop()
          </script> -->
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://nirvanalan.github.io/projects/E3DGE/index.html">
            <papertitle>E3DGE: Self-Supervised Geometry-Aware Encoder for Style-Based 3D GAN Inversion
            </papertitle>
          </a>
          <br>

          <a href="https://nirvanalan.github.io/">Yushi Lan</a>,
          <strong>Xuyi Meng</strong>,
          <a href='https://williamyang1991.github.io/' target='_blank'>Shuai Yang</a>,
          <a href='https://www.mmlab-ntu.com/person/ccloy/' target='_blank'>Chen Change Loy</a>,
          <a href='https://daibo.info/' target='_blank'>Bo Dai</a>
          <br>
          <em>CVPR</em>, 2023
          <br>
          <a href="https://nirvanalan.github.io/projects/E3DGE/index.html">project page</a>
          /
          <a href="https://arxiv.org/abs/2212.07409">arXiv</a>
          /
          <a href="https://drive.google.com/file/d/1yDkJfJOLeVlON7ZdRSnR34Ra_ikTVI0A/preview">video</a>
          /
          <a href="https://github.com/NIRVANALAN/CVPR23-E3DGE">Code</a>

          <p></p>
          <p>
            We propose E3DGE, an encoder-based 3D GAN inversion framework that yields high-quality shape and
            texture reconstruction.
          </p>
        </td>
      </tr>




      <!-- template -->
      <!-- <tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()" bgcolor="#ffffd0">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='dreamfusion_image'><video width=100% height=100% muted autoplay loop>
                        <source src="images/dreamfusion.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                      </video></div>
                    <img src='images/dreamfusion.jpg' width="160">
                  </div>
                  <script type="text/javascript">
                    function dreamfusion_start() {
                      document.getElementById('dreamfusion_image').style.opacity = "1";
                    }

                    function dreamfusion_stop() {
                      document.getElementById('dreamfusion_image').style.opacity = "0";
                    }
                    dreamfusion_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://dreamfusion3d.github.io/">
                    <papertitle>DreamFusion: Text-to-3D using 2D Diffusion</papertitle>
                  </a>
                  <br>
                  <a href="https://cs.stanford.edu/~poole/">Ben Poole</a>,
                  <a href="https://www.ajayj.com/">Ajay Jain</a>,
                  <strong>Jonathan T. Barron</strong>,
                  <a href="https://bmild.github.io/">Ben Mildenhall</a>
                  <br>
                  <em>arXiv</em>, 2022
                  <br>
                  <a href="https://dreamfusion3d.github.io/">project page</a>
                  /
                  <a href="https://arxiv.org/abs/2209.14988">arXiv</a>
                  /
                  <a href="https://dreamfusion3d.github.io/gallery.html">gallery</a>
                  <p></p>
                  <p>
                    We optimize a NeRF from scratch using a pretrained text-to-image diffusion model to do text-to-3D
                    generative modeling.
                  </p>
                </td>
              </tr> -->


    </tbody>
  </table>

  <!-- 
  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody>
      <tr>
        <td>
          <heading>Misc</heading>
        </td>
      </tr>
    </tbody>
  </table> -->
  <table width="100%" align="center" border="0" cellpadding="20">
    <!-- <tbody> -->

    <!-- <tr>
                <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>
                <td width="75%" valign="center">
                  <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>
                  <br>
                  <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair & Longuet-Higgins Award Committee Member,
                    CVPR 2021</a>
                  <br>
                  <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
                  <br>
                  <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
                </td> -->
    <!-- </tr> -->
    <!-- <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/cs188.jpg" alt="cs188">
                </td>
                <td width="75%" valign="center">
                  <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor,
                    CS188 Spring 2011</a>
                  <br>
                  <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor,
                    CS188 Fall 2010</a>
                  <br>
                  <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd
                    Edition</a>
                </td>
              </tr> -->


    <!-- <tr>
                <td align="center" style="padding:20px;width:25%;vertical-align:middle">
                  <heading>Basically <br> Blog Posts</heading>
                </td>
                <td width="75%" valign="middle">
                  <a href="https://arxiv.org/abs/2112.11687">Squareplus: A Softplus-Like Algebraic Rectifier</a>
                  <br>
                  <a href="https://arxiv.org/abs/2010.09714">A Convenient Generalization of Schlick's Bias and Gain
                    Functions</a>
                  <br>
                  <a href="https://arxiv.org/abs/1704.07483">Continuously Differentiable Exponential Linear Units</a>
                </td>
              </tr> -->


    </tbody>
  </table>

  <table style="width:70%;border:0px;border-spacing:0px;">
  <!-- <table > -->
    <tbody>
      <tr>
        <td style="padding:0px">
          <br>
          <p style="text-align:right;font-size:small;">
            Design and source code from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron's
              website</a>
          </p>
        </td>
      </tr>
    </tbody>
  </table>
  </td>
  </tr>
  </table>
</body>

</html>
